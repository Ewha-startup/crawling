import nest_asyncio
import asyncio
from playwright.async_api import async_playwright

nest_asyncio.apply()

LIST_URL = "https://www.musinsa.com/brand/musinsastandard/products?gf=A"

async def collect_product_links(page, max_scrolls=1):
    seen_names = set()
    products = []

    for _ in range(max_scrolls):
        product_cards = await page.query_selector_all('div.sc-widb61-1.dPWHpp')
        print(f"ğŸ“¦ í˜„ì¬ ë³´ì´ëŠ” ìƒí’ˆ ìˆ˜: {len(product_cards)}")

        for card in product_cards:
            name_el = await card.query_selector("a span[data-mds='Typography']")
            name = await name_el.inner_text() if name_el else None
            if not name or name in seen_names:
                continue
            seen_names.add(name)

            link_el = await card.query_selector("a")
            link_suffix = await link_el.get_attribute("href") if link_el else None
            link = f"https://www.musinsa.com{link_suffix}" if link_suffix and not link_suffix.startswith("http") else link_suffix

            # ì„±ë³„
            gender_el = await card.query_selector("div.sc-gnqCJb span")
            gender = await gender_el.inner_text() if gender_el else "?"

            # í• ì¸            discount_el = await card.query_selector("span:has-text('%')")
            discount_el = await card.query_selector("span:has-text('%')")
            discount = await discount_el.inner_text() if discount_el else "0%"

            # ê°€ê²©
            price_el = await card.query_selector("div.sc-hKDTPf span[data-mds='Typography']:nth-child(2)")
            price = await price_el.inner_text() if price_el else "?"

            # í‰ì 
            rating_el = await card.query_selector("span.text-yellow")
            rating = await rating_el.inner_text() if rating_el else "0"

            # \cc2c ìˆ˜
            likes_el = await card.query_selector("span.text-etc_11px_reg.text-red")
            likes = await likes_el.inner_text() if likes_el else "-"

            # ì´ë¯¸ì§€
            img_el = await card.query_selector("img")
            img_src = await img_el.get_attribute("src") if img_el else None
            if img_src and img_src.startswith("//"):
                img_src = "https:" + img_src

            products.append({
                "name": name,
                "gender": gender,
                "discount": discount,
                "price": price,
                "rating": rating,
                "likes": likes,
                "link": link,
                "image": img_src,
            })

        # ìŠ¤í¬ë¡¤
        await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
        await page.wait_for_timeout(1500)

    return products


async def main():
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)
        page = await browser.new_page()

        # 1. ëª©ë¡ ì§„ì…
        await page.goto(LIST_URL)
        await page.wait_for_load_state("networkidle")

        # 2. ì „ì²´ ìƒí’ˆ ë§í¬ ìˆ˜ì§‘
        product_list = await collect_product_links(page, max_scrolls=2)
        print(f"ğŸ“Ÿ ì´ ìˆ˜ì§‘ëœ ìƒí’ˆ ìˆ˜: {len(product_list)}\n")

        results = []

        # 3. ê° ìƒí’ˆ ìƒì„¸ í˜ì´ì§€ ë“¤ì–´ê°€ì„œ ì¹´í…Œê³ ë¦¬ + í•€/ê³„ì ˆê° ìˆ˜ì§‘
        for i, product in enumerate(product_list, start=1):
            link = product["link"]
            category = "N/A"
            fit_dict = {}

            try:
                await page.goto(link)
                await page.wait_for_load_state("networkidle")

                await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                await page.wait_for_timeout(3000)

                category_els = await page.query_selector_all("a[data-section-name='cate_navi'][data-button-name='ìƒí’ˆì¹´í…Œê³ ë¦¬']")
                categories = [await el.text_content() for el in category_els if el]
                category = categories[-1] if categories else "N/A"

                # í•/ê³„ì ˆê° ì •ë³´ ì¶”ì¶œ
                fit_keys = ["í•", "ì´‰ê°", "ì‹ ì¶•ì„±", "ë¹„ì¹¨", "ë‘ê»˜", "ê³„ì ˆ"]
                fit_dict = {}

                fit_elements = await page.query_selector_all(
                    'table.sc-36xiah-6.jizuRz > tbody > tr:not(:last-child) > td.sc-36xiah-7.eviTcu')
                fit_info = [await el.inner_text() for el in fit_elements]

                while len(fit_info) < 5:
                    fit_info.append("ì—†ìŒ")

                for j, key in enumerate(fit_keys[:-1]):
                    fit_dict[key] = fit_info[j]

                season_els = await page.query_selector_all(
                    'table.sc-36xiah-6.jizuRz > tbody > tr:last-child > td.sc-36xiah-7.eviTcu')
                seasons = [await el.inner_text() for el in season_els]
                fit_dict["ê³„ì ˆ"] = ", ".join(seasons) if seasons else "ì—†ìŒ"

                print(f"\nğŸ­ï¸ {i}. {product['name']}")
                print(f"   â”œ í• ì¸: {product['discount']}")
                print(f"   â”œ ê°€ê²©: {product['price']}")
                print(f"   â”œ ì°œ ìˆ˜: {product['likes']}")
                print(f"   â”œ í‰ì : {product['rating']}")
                print(f"   â”œ ì„±ë³„: {product['gender']}")
                print(f"   â”œ ì¹´í…Œê³ ë¦¬: {category}")
                print(f"   â”” ì´ë¯¸ì§€: {product['image']}")

                for key in fit_keys:
                    print(f"      - {key}: {fit_dict[key]}")

            except Exception as e:
                print(f"âš ï¸ ìƒì„¸ í˜ì´ì§€ ì§„ì… ì‹¤íŒ¨: {link} / ì˜¤ë¥˜: {e}")

            results.append({ **product, "category": category, **fit_dict })

            await page.goto(LIST_URL)
            await page.wait_for_load_state("networkidle")
            await page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            await page.wait_for_timeout(1500)

        await browser.close()

asyncio.run(main())